{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Average Word2Vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxuzxgyLGusM",
        "colab_type": "text"
      },
      "source": [
        "# Average Word2Vec Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvFCGMtPGaWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3fpLCR9G0pJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load preprocessed text\n",
        "review_data = pd.read_pickle(\"review_data.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ6-Q2cVG3In",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "0197910d-dc57-43f5-b5ab-733f304d8ffc"
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.3)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.139)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.139 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.139)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.0)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.139->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.139->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBZu8R0HHHk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "from nltk.tokenize import word_tokenize\n",
        "import multiprocessing\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-DuoGaeHNaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize all corpus and store in X_data_w2v\n",
        "def tokenize(review_data):\n",
        "  \"\"\"Input pandas dataFrame with Text Field Name and It return tokenize list\"\"\"\n",
        "  X_data_w2v = []\n",
        "  for i in range(review_data.shape[0]):\n",
        "      token = word_tokenize(review_data.Text.iloc[i])\n",
        "      X_data_w2v.append(token)\n",
        "  return X_data_w2v\n",
        "\n",
        "X_data_w2v = tokenize(review_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0jlLqxqHp52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train word2vec from scratch\n",
        "\n",
        "# cores = multiprocessing.cpu_count()\n",
        "# w2v_model = Word2Vec(min_count=1,\n",
        "#                      window=2,\n",
        "#                      size=100,\n",
        "#                      sample=6e-5, \n",
        "#                      alpha=0.03, \n",
        "#                      min_alpha=0.0007, \n",
        "#                      negative=20,\n",
        "#                      workers=cores-1)\n",
        "\n",
        "# Build vocabulary \n",
        "#w2v_model.build_vocab(X_data_w2v)\n",
        "# Training\n",
        "#w2v_model.train(X_data_w2v, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
        "\n",
        "\n",
        "\n",
        "#make model memory and execution efficient only after completed training.\n",
        "#w2v_model.init_sims(replace=True) \n",
        "\n",
        "# w2v_model.wv('Computer')\n",
        "# w2v_model.wv.most_similar(positive=[\"Excellent\"]) // similar word\n",
        "# w2v_model.wv.similarity(\"Queen\", 'Female') //similarity score\n",
        "# w2v_model.wv.doesnt_match(['Cat', 'Tiger', 'Chair']) //odd one out\n",
        "\n",
        "# Gives Train Accuracy 0.7959037165475416\n",
        "# Gives Test Accuracy0.7948192219679634"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd0f1XuPH1XZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for twitter trained word2vec\n",
        "\n",
        "#model = api.load(\"glove-twitter-25\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYg_Q35oHwpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Google News trained word2vec\n",
        "\n",
        "!wget \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
        "model_w2v = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz',binary=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LntRNu-ZH8DQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2aed1f15-9265-4afd-e64d-5c5f574be909"
      },
      "source": [
        "print(\"Vocabulary size of model : \",len(model_w2v.vocab))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size of model :  3000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKWXnhuBITyr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8a79a259-22c0-4a87-d143-f484819ffe33"
      },
      "source": [
        "def calculate_avg_w2v(X_data_w2v):\n",
        "  \"\"\"pass list of tokenize text return average word2vec\"\"\"\n",
        "  X_data_w2v1 = []\n",
        "  vocab_doc = []\n",
        "  X_data_w2v = np.array(X_data_w2v)\n",
        "\n",
        "  for i in range(len(X_data_w2v)):\n",
        "      for value in X_data_w2v[i]:\n",
        "          if value in model_w2v.vocab:\n",
        "              vocab_doc.append(value)\n",
        "      X_data_w2v[i]= vocab_doc\n",
        "      vocab_doc = []\n",
        "      temp = model_w2v.wv[X_data_w2v[i]]\n",
        "      doc_word = temp.shape[0]\n",
        "      temp = np.sum(temp,axis=0)/doc_word\n",
        "      X_data_w2v1.append(temp)\n",
        "  return X_data_w2v1\n",
        "\n",
        "X_data_w2v1 = calculate_avg_w2v(X_data_w2v)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysQZKxAPJlaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_data_w2v1 = np.array(X_data_w2v1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIlzxkDNJrtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stratified Test Train Spilt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X_data_w2v1,review_data.Sentiment,\n",
        "                                                 test_size=0.3,stratify=review_data.Sentiment,\n",
        "                                                 random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6x6y6fqJ5ch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f34070b2-ab95-4376-bb11-9973a6439415"
      },
      "source": [
        "print(\"Dimention of Review\",X_train.shape[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuPmdF-xKubT",
        "colab_type": "text"
      },
      "source": [
        "Note : Here Each Review represent by 300 dimension. less dimension means we can try various ML algorithm very fast. Unlike previous ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBilR_DjJ9H-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f2c202c1-5cce-4b1d-dcee-579cb35662d4"
      },
      "source": [
        "# Naive Bayes Algorithm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "clf =  GaussianNB()\n",
        "clf.fit(X_train,y_train)\n",
        "print(clf.score(X_train,y_train))\n",
        "print(clf.score(X_test,y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6830303553355249\n",
            "0.682233409610984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYMcqiDLLGnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "d121b6d2-adc7-4194-abe9-040830e71ca4"
      },
      "source": [
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf =  LogisticRegression()\n",
        "clf.fit(X_train,y_train)\n",
        "print(clf.score(X_train,y_train))\n",
        "print(clf.score(X_test,y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8969142534344916\n",
            "0.8961189931350114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POkzu4daLU05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1270
        },
        "outputId": "8b08c9df-5b89-4da0-d463-01ba1b9a9f6c"
      },
      "source": [
        "# Deep Learning Model\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "batch_size = 256\n",
        "epochs = 30\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_shape=(300,)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_test, y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 254914 samples, validate on 109250 samples\n",
            "Epoch 1/30\n",
            "254914/254914 [==============================] - 5s 21us/step - loss: 0.3152 - acc: 0.8679 - val_loss: 0.2593 - val_acc: 0.8897\n",
            "Epoch 2/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2567 - acc: 0.8928 - val_loss: 0.2498 - val_acc: 0.8944\n",
            "Epoch 3/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2508 - acc: 0.8960 - val_loss: 0.2455 - val_acc: 0.8971\n",
            "Epoch 4/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2463 - acc: 0.8984 - val_loss: 0.2428 - val_acc: 0.8987\n",
            "Epoch 5/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2433 - acc: 0.8997 - val_loss: 0.2406 - val_acc: 0.8994\n",
            "Epoch 6/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2403 - acc: 0.9007 - val_loss: 0.2372 - val_acc: 0.9010\n",
            "Epoch 7/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2379 - acc: 0.9022 - val_loss: 0.2378 - val_acc: 0.9012\n",
            "Epoch 8/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2357 - acc: 0.9029 - val_loss: 0.2349 - val_acc: 0.9031\n",
            "Epoch 9/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2338 - acc: 0.9040 - val_loss: 0.2318 - val_acc: 0.9034\n",
            "Epoch 10/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2323 - acc: 0.9049 - val_loss: 0.2333 - val_acc: 0.9023\n",
            "Epoch 11/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2307 - acc: 0.9051 - val_loss: 0.2300 - val_acc: 0.9045\n",
            "Epoch 12/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2294 - acc: 0.9061 - val_loss: 0.2275 - val_acc: 0.9059\n",
            "Epoch 13/30\n",
            "254914/254914 [==============================] - 4s 16us/step - loss: 0.2276 - acc: 0.9068 - val_loss: 0.2350 - val_acc: 0.9006\n",
            "Epoch 14/30\n",
            "254914/254914 [==============================] - 4s 17us/step - loss: 0.2261 - acc: 0.9070 - val_loss: 0.2249 - val_acc: 0.9070\n",
            "Epoch 15/30\n",
            "254914/254914 [==============================] - 4s 16us/step - loss: 0.2248 - acc: 0.9079 - val_loss: 0.2244 - val_acc: 0.9070\n",
            "Epoch 16/30\n",
            "254914/254914 [==============================] - 4s 17us/step - loss: 0.2234 - acc: 0.9085 - val_loss: 0.2258 - val_acc: 0.9066\n",
            "Epoch 17/30\n",
            "254914/254914 [==============================] - 4s 16us/step - loss: 0.2225 - acc: 0.9089 - val_loss: 0.2231 - val_acc: 0.9071\n",
            "Epoch 18/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2210 - acc: 0.9095 - val_loss: 0.2215 - val_acc: 0.9078\n",
            "Epoch 19/30\n",
            "254914/254914 [==============================] - 4s 16us/step - loss: 0.2201 - acc: 0.9099 - val_loss: 0.2222 - val_acc: 0.9084\n",
            "Epoch 20/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2187 - acc: 0.9108 - val_loss: 0.2235 - val_acc: 0.9086\n",
            "Epoch 21/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2178 - acc: 0.9111 - val_loss: 0.2202 - val_acc: 0.9090\n",
            "Epoch 22/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2161 - acc: 0.9117 - val_loss: 0.2200 - val_acc: 0.9085\n",
            "Epoch 23/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2153 - acc: 0.9122 - val_loss: 0.2186 - val_acc: 0.9094\n",
            "Epoch 24/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2145 - acc: 0.9124 - val_loss: 0.2191 - val_acc: 0.9096\n",
            "Epoch 25/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2130 - acc: 0.9133 - val_loss: 0.2170 - val_acc: 0.9100\n",
            "Epoch 26/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2120 - acc: 0.9132 - val_loss: 0.2169 - val_acc: 0.9102\n",
            "Epoch 27/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2116 - acc: 0.9135 - val_loss: 0.2166 - val_acc: 0.9103\n",
            "Epoch 28/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2109 - acc: 0.9140 - val_loss: 0.2158 - val_acc: 0.9119\n",
            "Epoch 29/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2098 - acc: 0.9146 - val_loss: 0.2165 - val_acc: 0.9111\n",
            "Epoch 30/30\n",
            "254914/254914 [==============================] - 4s 15us/step - loss: 0.2090 - acc: 0.9151 - val_loss: 0.2152 - val_acc: 0.9115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcmR1xOxLcrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6a415c71-4496-43ee-ec2c-2094adeb5525"
      },
      "source": [
        "# Best Accurcy given by MLP model\n",
        "print('Train Accuracy:',model.evaluate(X_train, y_train, verbose=0)[1])\n",
        "print('Test Accuracy:',model.evaluate(X_test, y_test, verbose=0)[1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.917882109260378\n",
            "Test Accuracy: 0.9114782608695652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSF6uiUqLofd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "cb4ee314-c379-4287-ed1f-7338c6d53b60"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cnf = confusion_matrix(y_test,clf.predict(X_test))\n",
        "sns.heatmap(cnf,annot=True,fmt='g',cmap=\"YlGnBu\");\n",
        "plt.title(\"Average Word2Vec with Deep learning\");"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEICAYAAACUOKXLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrmDwbKCMCTh",
        "colab_type": "text"
      },
      "source": [
        "Our Average Word2Vec Apppoch Gives Good Result but This approch don't outperform previous one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWm94uGsL4JS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}